{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c86cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import dnest4 as dn4\n",
    "from pyblobby3d import PostBlobby3D\n",
    "from pyblobby3d import SpectralModel\n",
    "from scipy.interpolate import RegularGridInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0eeabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the directory containing the data and the output\n",
    "dir_path = '/Users/scol0322/Documents/processed/485885-windowed/'\n",
    "data_file = '/Users/scol0322/Documents/raw-data/485885/485885_8_Y13SAR1_P007_15T010_2013_03_05-2013_03_17_1_comp.fits'\n",
    "\n",
    "# check if directories and files exist\n",
    "if not os.path.exists(dir_path):\n",
    "    raise FileNotFoundError(f\"Directory not found: {dir_path}\")\n",
    "if not os.path.exists(data_file):\n",
    "    raise FileNotFoundError(f\"Velocity data file not found: {data_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86ec06a",
   "metadata": {},
   "source": [
    "DNest post processing call only works if you call it from within the directory.\n",
    "\n",
    "Save current dir, hop there, call DNest, hop back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fd1dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save current directory\n",
    "original_dir = os.getcwd()\n",
    "\n",
    "def run_dnest4_postprocessing(dir_path):\n",
    "    \"\"\"run dnest4 postprocessing in the specified directory.\"\"\"\n",
    "    try:\n",
    "        os.chdir(dir_path)\n",
    "        dn4.postprocess()\n",
    "    finally:\n",
    "        os.chdir(original_dir)\n",
    "\n",
    "#run_dnest4_postprocessing(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a93f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for reading the options file\n",
    "# specifically the lines and global LSF FWHM (not really used)\n",
    "def read_options_file(options_file):\n",
    "    \"\"\"read the options file to extract emission lines and nlines.\"\"\"\n",
    "    lines = []\n",
    "    lsf_fwhm = None\n",
    "    \n",
    "    if not os.path.exists(options_file):\n",
    "        print(f\"Warning: Options file not found: {options_file}\")\n",
    "        return [], 0, None\n",
    "    \n",
    "    try:\n",
    "        with open(options_file, 'r') as f:\n",
    "            for line in f:\n",
    "                # skip comments and empty lines\n",
    "                if line.strip().startswith('#') or not line.strip():\n",
    "                    continue\n",
    "                \n",
    "                # remove inline comments\n",
    "                if '#' in line:\n",
    "                    line = line[:line.index('#')]\n",
    "                \n",
    "                parts = line.strip().split()\n",
    "                if not parts:\n",
    "                    continue\n",
    "                \n",
    "                if parts[0].upper() == 'LINE':\n",
    "                    # parse line definition: LINE main_wavelength [coupled_wavelength1 ratio1 ...]\n",
    "                    line_data = []\n",
    "                    for i, part in enumerate(parts[1:]):\n",
    "                        try:\n",
    "                            line_data.append(float(part))\n",
    "                        except ValueError:\n",
    "                            break\n",
    "                    \n",
    "                    if line_data:\n",
    "                        lines.append(line_data)\n",
    "                \n",
    "                elif parts[0].upper() == 'LSFFWHM':\n",
    "                    try:\n",
    "                        lsf_fwhm = float(parts[1])\n",
    "                    except (ValueError, IndexError):\n",
    "                        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading options file: {e}\")\n",
    "        return [], 0, None\n",
    "    \n",
    "    nlines = len(lines)\n",
    "    return lines, nlines, lsf_fwhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc524392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for reading the metadata file\n",
    "# specifically the waveranges and the coords\n",
    "def read_metadata_file(metadata_file):\n",
    "    \"\"\"read metadata file to get resolution, calculate lsf_fwhm, and extract coordinate info.\"\"\"\n",
    "    wavelength_windows = []\n",
    "    coord_info = {}\n",
    "    \n",
    "    if not os.path.exists(metadata_file):\n",
    "        print(f\"Warning: Metadata file not found: {metadata_file}\")\n",
    "        return [], {}\n",
    "    \n",
    "    try:\n",
    "        with open(metadata_file, 'r') as f:\n",
    "            for line in f:\n",
    "                # skip comments and empty lines\n",
    "                if line.strip().startswith('#') or not line.strip():\n",
    "                    continue\n",
    "                \n",
    "                # remove inline comments\n",
    "                if '#' in line:\n",
    "                    line = line[:line.index('#')]\n",
    "                \n",
    "                parts = line.strip().split()\n",
    "                if not parts:\n",
    "                    continue\n",
    "                \n",
    "                if parts[0].upper() == 'WAVE_RANGE' and len(parts) >= 6:\n",
    "                    r_min = float(parts[1])\n",
    "                    r_max = float(parts[2])\n",
    "                    try:\n",
    "                        # first try 7th column (index 6)\n",
    "                        if len(parts) > 6:\n",
    "                            lsf_fwhm = float(parts[6])\n",
    "                        else:\n",
    "                            lsf_fwhm = 1.5\n",
    "                    except (ValueError, IndexError):\n",
    "                        # fallback calculation\n",
    "                        lsf_fwhm = 1.5\n",
    "\n",
    "                    wavelength_windows.append({\n",
    "                        'r_min': r_min,\n",
    "                        'r_max': r_max,\n",
    "                        'lsf_fwhm': lsf_fwhm\n",
    "                    })\n",
    "                \n",
    "                # read coordinate information\n",
    "                elif parts[0].lower() in ['ni', 'nj', 'x_min', 'x_max', 'y_min', 'y_max']:\n",
    "                    try:\n",
    "                        coord_info[parts[0].lower()] = float(parts[1])\n",
    "                    except (ValueError, IndexError):\n",
    "                        pass\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading metadata file: {e}\")\n",
    "        return [], {}\n",
    "    \n",
    "    return wavelength_windows, coord_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1eadb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_axes_with_coordinates(ax, coord_info):\n",
    "    \"\"\"setup axes with delta RA and delta Dec labels.\"\"\"\n",
    "    if not coord_info:\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        ni = int(coord_info.get('ni'))\n",
    "        nj = int(coord_info.get('nj'))\n",
    "        x_min = coord_info.get('x_min')  # delta ra in arcsec\n",
    "        x_max = coord_info.get('x_max')\n",
    "        y_min = coord_info.get('y_min')  # delta dec in arcsec\n",
    "        y_max = coord_info.get('y_max')\n",
    "        \n",
    "        # set up ticks and labels\n",
    "        # x-axis (ra): note that ra increases to the left (east)\n",
    "        x_pixel_coords = np.linspace(0, nj-1, 5)  # 5 tick marks\n",
    "        x_arcsec_coords = x_min + (x_pixel_coords / (nj-1)) * (x_max - x_min)\n",
    "        ax.set_xticks(x_pixel_coords)\n",
    "        ax.set_xticklabels([f'{-x:.1f}' for x in x_arcsec_coords])  # negative for ra convention\n",
    "        ax.set_xlabel('Δ RA (arcsec)')\n",
    "        \n",
    "        # y-axis (dec)\n",
    "        y_pixel_coords = np.linspace(0, ni-1, 5)  # 5 tick marks\n",
    "        y_arcsec_coords = y_min + (y_pixel_coords / (ni-1)) * (y_max - y_min)\n",
    "        ax.set_yticks(y_pixel_coords)\n",
    "        ax.set_yticklabels([f'{y:.1f}' for y in y_arcsec_coords])\n",
    "        ax.set_ylabel('Δ Dec (arcsec)')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: could not set coordinate axes: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e2680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectral_model_with_validation(emission_lines, lsf_fwhm_map, metadata):\n",
    "    \"\"\"create SpectralModel with validation and error handling.\"\"\"\n",
    "    try:\n",
    "        # create the spectral model\n",
    "        sm = SpectralModel(\n",
    "            lines=emission_lines,\n",
    "            lsf_fwhm=lsf_fwhm_map,\n",
    "            wavelength_windows=getattr(metadata, 'wavelength_windows', [])\n",
    "        )\n",
    "        \n",
    "        # print summary if method exists\n",
    "        if hasattr(sm, 'print_line_summary'):\n",
    "            sm.print_line_summary()\n",
    "        \n",
    "        # validate that lines are in windows if method exists\n",
    "        if hasattr(sm, 'validate_lines_in_windows'):\n",
    "            validation = sm.validate_lines_in_windows()\n",
    "            if not validation.get('all_valid', True):\n",
    "                print(\"\\n!!!!! Warning: Some issues found with line-window compatibility:\")\n",
    "                for warning in validation.get('warnings', []):\n",
    "                    print(f\"  {warning}\")\n",
    "        \n",
    "        return sm\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"!!!!!! ERROR creating SpectralModel: {e}\")\n",
    "        print(\"Falling back to default configuration...\")\n",
    "        \n",
    "        # fallback to simple configuration\n",
    "        fallback_lines = [[6562.81], [6583.1, 6548.1, 0.3333]][:len(emission_lines)] if emission_lines else [[6562.81]]\n",
    "        try:\n",
    "            sm = SpectralModel(\n",
    "                lines=fallback_lines,\n",
    "                lsf_fwhm=1.61  # use global default\n",
    "            )\n",
    "            return sm\n",
    "        except Exception as e2:\n",
    "            print(f\"Even fallback failed: {e2}\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467f0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_velocity_data(v_data_file, v_extension='V', vdisp_extension='VDISP'):\n",
    "    \"\"\"read the actual velocity data from FITS file.\"\"\"\n",
    "    print(f\"Reading velocity data from: {v_data_file}\")\n",
    "    \n",
    "    try:\n",
    "        with fits.open(v_data_file) as hdul:\n",
    "            # print available extensions for debugging\n",
    "            print(\"Available FITS extensions:\")\n",
    "            for i, hdu in enumerate(hdul):\n",
    "                print(f\"  {i}: {hdu.name} - {type(hdu).__name__}\")\n",
    "            \n",
    "            # try to find velocity extensions\n",
    "            v_data = None\n",
    "            vdisp_data = None\n",
    "            \n",
    "            for ext_name in [v_extension, v_extension.upper(), v_extension.lower()]:\n",
    "                if ext_name in hdul:\n",
    "                    v_data = hdul[ext_name].data\n",
    "                    break\n",
    "            \n",
    "            for ext_name in [vdisp_extension, vdisp_extension.upper(), vdisp_extension.lower()]:\n",
    "                if ext_name in hdul:\n",
    "                    vdisp_data = hdul[ext_name].data\n",
    "                    break\n",
    "            \n",
    "            if v_data is None or vdisp_data is None:\n",
    "                raise ValueError(f\"Could not find velocity extensions '{v_extension}' and '{vdisp_extension}'\")\n",
    "            \n",
    "            print(f\"Velocity cube shape: {v_data.shape}\")\n",
    "            print(f\"Velocity dispersion cube shape: {vdisp_data.shape}\")\n",
    "            \n",
    "            # handle different data structures\n",
    "            if len(v_data.shape) == 3:\n",
    "                # extract the valid slice (assuming [1,:,:] contains the data)\n",
    "                v_2d = v_data[1, :, :] if v_data.shape[0] > 1 else v_data[0, :, :]\n",
    "                vdisp_2d = vdisp_data[1, :, :] if vdisp_data.shape[0] > 1 else vdisp_data[0, :, :]\n",
    "            elif len(v_data.shape) == 2:\n",
    "                v_2d = v_data\n",
    "                vdisp_2d = vdisp_data\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected data shape: {v_data.shape}\")\n",
    "            \n",
    "            print(f\"Extracted 2D velocity shape: {v_2d.shape}\")\n",
    "            print(f\"Extracted 2D velocity dispersion shape: {vdisp_2d.shape}\")\n",
    "            \n",
    "            return v_2d, vdisp_2d\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading velocity data: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a561ada6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read emission lines and metadata from files\n",
    "options_file = os.path.join(dir_path, 'MODEL_OPTIONS')\n",
    "emission_lines, nlines, lsf_fwhm_global = read_options_file(options_file)\n",
    "\n",
    "if nlines == 0:\n",
    "    print(\"Warning: No emission lines detected, using defaults\")\n",
    "else:\n",
    "    print(f\"Number of emission lines detected: {nlines}\")\n",
    "    print(\"Emission lines:\")\n",
    "    for i, line in enumerate(emission_lines):\n",
    "        if len(line) == 1:\n",
    "            print(f\"  Line {i+1}: {line[0]} Å (single line)\")\n",
    "        else:\n",
    "            main_line = line[0]\n",
    "            coupled_info = []\n",
    "            for j in range(1, len(line), 2):\n",
    "                if j+1 < len(line):\n",
    "                    coupled_wave = line[j]\n",
    "                    ratio = line[j+1]\n",
    "                    coupled_info.append(f\"{coupled_wave} Å (ratio: {ratio})\")\n",
    "            print(f\"  Line {i+1}: {main_line} Å + coupled lines: {', '.join(coupled_info)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e334a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read wavelength windows and coordinate info from metadata file\n",
    "metadata_file = os.path.join(dir_path, 'metadata.txt')\n",
    "wavelength_windows, coord_info = read_metadata_file(metadata_file)\n",
    "print(f\"Number of wavelength windows: {len(wavelength_windows)}\")\n",
    "print(f\"Coordinate info: {coord_info}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eefabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary mapping window index to lsf_fwhm for multi-window support\n",
    "lsf_fwhm_map = {}\n",
    "if wavelength_windows:\n",
    "    for i, window in enumerate(wavelength_windows):\n",
    "        lsf_fwhm_map[i] = window['lsf_fwhm']\n",
    "        print(f\"Window {i+1}: λ={window['r_min']:.1f}-{window['r_max']:.1f} Å, \"\n",
    "              f\"LSF_FWHM={window['lsf_fwhm']:.3f} Å\")\n",
    "else:\n",
    "    print(\"Using default LSF FWHM\")\n",
    "    lsf_fwhm_map = lsf_fwhm_global or 1.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe557a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PostBlobby3D object with error handling\n",
    "try:\n",
    "    post_b3d = PostBlobby3D(\n",
    "        samples_path=os.path.join(dir_path, 'posterior_sample.txt'),\n",
    "        data_path=os.path.join(dir_path, 'data.txt'),\n",
    "        var_path=os.path.join(dir_path, 'var.txt'),\n",
    "        metadata_path=os.path.join(dir_path, 'metadata.txt'),\n",
    "        nlines=nlines)\n",
    "    print(\"PostBlobby3D object created successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating PostBlobby3D object: {e}\")\n",
    "    print(\"This might be due to missing files or incorrect file formats\")\n",
    "    exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c27a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a sample\n",
    "sample = 0\n",
    "\n",
    "# check if we have enough data for plotting\n",
    "if post_b3d.maps.shape[0] <= sample:\n",
    "    print(f\"Error: Sample {sample} not available. Available samples: {post_b3d.maps.shape[0]}\")\n",
    "    sample = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dea66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot maps for sample - now supporting multiple lines with coordinate axes\n",
    "try:\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "    # plot maps for all detected lines\n",
    "    for line_idx in range(min(nlines, 2)):  # limit to first 2 lines for display\n",
    "        if line_idx == 0:\n",
    "            # first line - typically h-alpha\n",
    "            main_wave = emission_lines[0][0] if emission_lines else 6562.81\n",
    "            if abs(main_wave - 6562.81) < 0.1:\n",
    "                title = r'H$\\alpha$ Flux'\n",
    "            else:\n",
    "                title = f'Line 1 ({main_wave:.1f} Å) Flux'\n",
    "        elif line_idx == 1:\n",
    "            # second line - typically [nii]\n",
    "            main_wave = emission_lines[1][0] if len(emission_lines) > 1 else 6583.1\n",
    "            if abs(main_wave - 6583.1) < 0.1:\n",
    "                title = r'[NII] Flux'\n",
    "            else:\n",
    "                title = f'Line 2 ({main_wave:.1f} Å) Flux'\n",
    "        \n",
    "        ax[line_idx].set_title(title)\n",
    "        flux_map = post_b3d.maps[sample, line_idx]\n",
    "        # handle zero or negative fluxes in log plot\n",
    "        flux_map_safe = np.where(flux_map > 0, flux_map, np.nan)\n",
    "        im = ax[line_idx].imshow(\n",
    "            np.log10(flux_map_safe),\n",
    "            interpolation='nearest', origin='lower')\n",
    "        plt.colorbar(im, ax=ax[line_idx], label='log10(Flux)')\n",
    "        setup_axes_with_coordinates(ax[line_idx], coord_info)\n",
    "\n",
    "    # if only one line detected, show placeholder for second\n",
    "    if nlines < 2:\n",
    "        ax[1].set_title('No Second Line')\n",
    "        ax[1].text(0.5, 0.5, 'N/A', ha='center', va='center', transform=ax[1].transAxes)\n",
    "        ax[1].set_xticks([])\n",
    "        ax[1].set_yticks([])\n",
    "\n",
    "    ax[2].set_title('V (km/s)')\n",
    "    im2 = ax[2].imshow(post_b3d.maps[sample, nlines], interpolation='nearest', origin='lower')\n",
    "    plt.colorbar(im2, ax=ax[2], label='km/s')\n",
    "    setup_axes_with_coordinates(ax[2], coord_info)\n",
    "\n",
    "    ax[3].set_title('V Disp (km/s)')\n",
    "    im3 = ax[3].imshow(post_b3d.maps[sample, nlines+1], interpolation='nearest', origin='lower')\n",
    "    plt.colorbar(im3, ax=ax[3], label='km/s')\n",
    "    setup_axes_with_coordinates(ax[3], coord_info)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating initial plots: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656c1732",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "    ax[0].set_title('Preconvolved')\n",
    "    preconv_sum = post_b3d.precon_cubes[sample].sum(axis=2)\n",
    "    preconv_sum_safe = np.where(preconv_sum > 0, preconv_sum, np.nan)\n",
    "    im0 = ax[0].imshow(np.log10(preconv_sum_safe), interpolation='nearest', origin='lower')\n",
    "    plt.colorbar(im0, ax=ax[0])\n",
    "    setup_axes_with_coordinates(ax[0], coord_info)\n",
    "\n",
    "    ax[1].set_title('Convolved')\n",
    "    conv_sum = post_b3d.con_cubes[sample].sum(axis=2)\n",
    "    conv_sum_safe = np.where(conv_sum > 0, conv_sum, np.nan)\n",
    "    im1 = ax[1].imshow(np.log10(conv_sum_safe), interpolation='nearest', origin='lower')\n",
    "    plt.colorbar(im1, ax=ax[1])\n",
    "    setup_axes_with_coordinates(ax[1], coord_info)\n",
    "\n",
    "    ax[2].set_title('Data')\n",
    "    data_sum = post_b3d.data.sum(axis=2)\n",
    "    data_sum_safe = np.where(data_sum > 0, data_sum, np.nan)\n",
    "    im2 = ax[2].imshow(np.log10(data_sum_safe), interpolation='nearest', origin='lower')\n",
    "    plt.colorbar(im2, ax=ax[2])\n",
    "    setup_axes_with_coordinates(ax[2], coord_info)\n",
    "\n",
    "    ax[3].set_title('Residuals (data - convolved)')\n",
    "    residual_map = (np.log10(data_sum_safe) - np.log10(conv_sum_safe))\n",
    "    im3 = ax[3].imshow(residual_map, interpolation='nearest', origin='lower', cmap='RdBu_r')\n",
    "    # add colorbar to make sure the centre is white\n",
    "    cbar = plt.colorbar(im3, ax=ax[3])\n",
    "    cbar.set_label('Residual (log scale)')\n",
    "    setup_axes_with_coordinates(ax[3], coord_info)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating flux comparison plots: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot showing the residuals at each central line location for all windows\n",
    "if len(wavelength_windows) > 0:\n",
    "    try:\n",
    "        fig, axes = plt.subplots(1, len(wavelength_windows), figsize=(5*len(wavelength_windows), 4))\n",
    "        if len(wavelength_windows) == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        central_i, central_j = post_b3d.data.shape[0]//2, post_b3d.data.shape[1]//2\n",
    "\n",
    "        for w, window in enumerate(wavelength_windows):\n",
    "            # find the wavelength indices for this window more carefully\n",
    "            r_full = post_b3d.metadata.r_full\n",
    "            \n",
    "            # find indices within this window's range\n",
    "            window_mask = (r_full >= window['r_min']) & (r_full <= window['r_max'])\n",
    "            window_indices = np.where(window_mask)[0]\n",
    "            \n",
    "            if len(window_indices) == 0:\n",
    "                # no data in this window\n",
    "                axes[w].text(0.5, 0.5, 'No data\\nin window', ha='center', va='center', \n",
    "                            transform=axes[w].transAxes)\n",
    "                axes[w].set_title(f'Window {w+1}: {window[\"r_min\"]:.0f}-{window[\"r_max\"]:.0f} Å')\n",
    "                continue\n",
    "            \n",
    "            wavelengths = r_full[window_indices]\n",
    "            data_spectrum = post_b3d.data[central_i, central_j, window_indices]\n",
    "            model_spectrum = post_b3d.con_cubes[sample, central_i, central_j, window_indices]\n",
    "            residuals = data_spectrum - model_spectrum\n",
    "            \n",
    "            axes[w].plot(wavelengths, data_spectrum, 'k-', label='Data', alpha=0.7, linewidth=1.5)\n",
    "            axes[w].plot(wavelengths, model_spectrum, 'r-', label='Model', linewidth=1.5)\n",
    "            axes[w].plot(wavelengths, residuals, 'b-', label='Residuals', alpha=0.7)\n",
    "            \n",
    "            axes[w].set_xlabel('Wavelength (Å)')\n",
    "            axes[w].set_ylabel('Flux')\n",
    "            axes[w].set_title(f'Window {w+1}: {window[\"r_min\"]:.0f}-{window[\"r_max\"]:.0f} Å')\n",
    "            axes[w].legend()\n",
    "            axes[w].grid(True, alpha=0.3)\n",
    "\n",
    "        fig.suptitle(f'Spectral fit at central spaxel ({central_i}, {central_j})')\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating spectral fit plots: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfec000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot integrated spectrum\n",
    "try:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # plot data\n",
    "    ax.plot(post_b3d.metadata.r_full, post_b3d.data.sum(axis=(0, 1)), \n",
    "            '--k', label='Data', linewidth=2)\n",
    "\n",
    "    # plot model samples\n",
    "    n_samples_to_plot = min(5, post_b3d.con_cubes.shape[0])\n",
    "    for s in range(n_samples_to_plot):\n",
    "        alpha = 0.3 if s > 0 else 0.8\n",
    "        label = 'Models' if s == 0 else None\n",
    "        ax.plot(post_b3d.metadata.r_full, post_b3d.con_cubes[s].sum(axis=(0, 1)), \n",
    "                color='red', alpha=alpha, label=label)\n",
    "\n",
    "    ax.set_xlabel('Wavelength (Å)')\n",
    "    ax.set_ylabel('Integrated Flux')\n",
    "    ax.set_title('Integrated flux across all spaxels')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "    # highlight wavelength windows\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    for w, window in enumerate(wavelength_windows):\n",
    "        color = f'C{w % 10}'  # cycle through colours\n",
    "        ax.axvspan(window['r_min'], window['r_max'], alpha=0.1, \n",
    "                   color=color, label=f'Window {w+1}' if w < 5 else None)\n",
    "\n",
    "    # add vertical lines for emission lines\n",
    "    for i, line in enumerate(emission_lines):\n",
    "        main_wave = line[0]\n",
    "        ax.axvline(main_wave, color=f'C{i % 10}', linestyle=':', alpha=0.7, \n",
    "                   label=f'Line {i+1}: {main_wave:.1f} Å' if i < 3 else None)\n",
    "        \n",
    "        # add coupled lines\n",
    "        if len(line) > 1:\n",
    "            for j in range(1, len(line), 2):\n",
    "                if j+1 < len(line):\n",
    "                    coupled_wave = line[j]\n",
    "                    ax.axvline(coupled_wave, color=f'C{i % 10}', linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating integrated spectrum plot: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38afbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lsf_fwhm_map)\n",
    "print(emission_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a13f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SpectralModel with validation\n",
    "sm = create_spectral_model_with_validation(emission_lines, lsf_fwhm_map, post_b3d.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041d3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the data cube if spectral model was created successfully\n",
    "fit = None\n",
    "fit_err = None\n",
    "\n",
    "if sm is not None:\n",
    "    try:\n",
    "        print(\"Fitting data cube...\")\n",
    "        wave = post_b3d.metadata.get_axis_array('r')\n",
    "        fit, fit_err = sm.fit_cube(wave, post_b3d.data, post_b3d.var)\n",
    "        print(f\"Fit successful. Fit shape: {fit.shape}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fitting cube: {e}\")\n",
    "        print(\"Continuing without fit results...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad9029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# velocity comparison plots\n",
    "try:\n",
    "    # velocity comparison\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    fig.suptitle('Velocity Comparison')\n",
    "\n",
    "    v_map_idx = nlines \n",
    "\n",
    "    # preconvolved velocity\n",
    "    vmin, vmax = -100, 100\n",
    "    im1 = ax[0].imshow(post_b3d.maps[sample, v_map_idx], vmin=vmin, vmax=vmax, \n",
    "                       origin='lower', cmap='viridis')\n",
    "    ax[0].set_title('Preconvolved V (km/s)')\n",
    "    plt.colorbar(im1, ax=ax[0], label='km/s')\n",
    "    setup_axes_with_coordinates(ax[0], coord_info)\n",
    "\n",
    "    # fitted velocity from convolved data\n",
    "    if fit is not None and fit.shape[0] > 2:  # ensure we have velocity in fit results\n",
    "        im2 = ax[1].imshow(fit[2], vmin=vmin, vmax=vmax, origin='lower', cmap='viridis')\n",
    "        ax[1].set_title('Fitted V (km/s)')\n",
    "        plt.colorbar(im2, ax=ax[1], label='km/s')\n",
    "        setup_axes_with_coordinates(ax[1], coord_info)\n",
    "    else:\n",
    "        ax[1].text(0.5, 0.5, 'Fit failed\\nor insufficient\\nparameters', \n",
    "                   ha='center', va='center', transform=ax[1].transAxes)\n",
    "        ax[1].set_title('Fitted V (Failed)')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # velocity dispersion comparison\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    fig.suptitle('Velocity Dispersion Comparison')\n",
    "\n",
    "    vdisp_map_idx = nlines + 1  # velocity dispersion is after flux and velocity maps\n",
    "\n",
    "    # preconvolved velocity dispersion\n",
    "    vmin, vmax = 0.0, 80.0\n",
    "    im1 = ax[0].imshow(post_b3d.maps[sample, vdisp_map_idx], vmin=vmin, vmax=vmax, \n",
    "                       origin='lower', cmap='viridis')\n",
    "    ax[0].set_title('Preconvolved V Disp (km/s)')\n",
    "    plt.colorbar(im1, ax=ax[0], label='km/s')\n",
    "    setup_axes_with_coordinates(ax[0], coord_info)\n",
    "\n",
    "    # fitted velocity dispersion from convolved data\n",
    "    if fit is not None and fit.shape[0] > 3:  # ensure we have velocity dispersion in fit results\n",
    "        im2 = ax[1].imshow(fit[3], vmin=vmin, vmax=vmax, origin='lower', cmap='viridis')\n",
    "        ax[1].set_title('Fitted V Disp (km/s)')\n",
    "        plt.colorbar(im2, ax=ax[1], label='km/s')\n",
    "        setup_axes_with_coordinates(ax[1], coord_info)\n",
    "    else:\n",
    "        ax[1].text(0.5, 0.5, 'Fit failed\\nor insufficient\\nparameters', \n",
    "                   ha='center', va='center', transform=ax[1].transAxes)\n",
    "        ax[1].set_title('Fitted V Disp (Failed)')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error creating velocity comparison plots: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff823921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading velocity data\n",
    "data_v_2d, data_vdisp_2d = read_velocity_data(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed233672",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coord_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def align_velocity_data(data_2d, model_2d, coord_info):\n",
    "    \"\"\"align velocity data with PostBlobby3D maps.\"\"\"\n",
    "    if data_2d is None or model_2d is None:\n",
    "        print(\"Error: No velocity data available for alignment\")\n",
    "        return None\n",
    "    try:\n",
    "        x_range = [coord_info.get('x_min'), coord_info.get('x_max')]\n",
    "        y_range = [coord_info.get('y_min'), coord_info.get('y_max')]\n",
    "\n",
    "        x_arcsec_per_pix = (x_range[1] - x_range[0]) / coord_info.get('nj')\n",
    "        y_arcsec_per_pix = (y_range[1] - y_range[0]) / coord_info.get('ni')\n",
    "\n",
    "        data_shape = data_2d.shape\n",
    "\n",
    "        x_range_data = [-data_shape[0]/2 * x_arcsec_per_pix,\n",
    "                        data_shape[0]/2 * x_arcsec_per_pix]\n",
    "        y_range_data = [-data_shape[1]/2 * y_arcsec_per_pix,\n",
    "                        data_shape[1]/2 * y_arcsec_per_pix]\n",
    "        \n",
    "        print(f\"Aligning velocity data with ranges: {x_range_data}, {y_range_data}\")\n",
    "\n",
    "        #check data range is larger than model range\n",
    "        if (x_range_data[0] > x_range[0] or x_range_data[1] < x_range[1] or\n",
    "            y_range_data[0] > y_range[0] or y_range_data[1] < y_range[1]):\n",
    "            print(\"Error: Data range is smaller than model range, cannot align\")\n",
    "            return None \n",
    "\n",
    "        # indexes to remove from the data\n",
    "        x_start = abs(int((x_range_data[0] - x_range[0]) / x_arcsec_per_pix))\n",
    "        x_end = 50 - abs(int((x_range_data[1] - x_range[1]) / x_arcsec_per_pix))\n",
    "        y_start = abs(int((y_range_data[1] - y_range[1]) / y_arcsec_per_pix))\n",
    "        y_end = 50 - abs(int((y_range_data[0] - y_range[0]) / y_arcsec_per_pix))\n",
    "        print(f\"Data slice: x[{x_start}:{x_end}], y[{y_start}:{y_end}]\")    \n",
    "\n",
    "        # slice the data to match the model\n",
    "        # flipped for some reason\n",
    "        aligned_data = data_2d[y_start:y_end, x_start:x_end]\n",
    "\n",
    "        if aligned_data.shape != model_2d.shape:\n",
    "            print(f\"Error: Aligned data shape {aligned_data.shape} does not match model shape {model_2d.shape}\")\n",
    "            return None\n",
    "        \n",
    "        return aligned_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error aligning velocity data: {e}\")\n",
    "        return None\n",
    "\n",
    "aligned_v = align_velocity_data(data_v_2d, fit[2], coord_info)\n",
    "aligned_vdisp = align_velocity_data(data_vdisp_2d, fit[3], coord_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9213ec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_comparison_plot(post_b3d, fit, sample, nlines, coord_info, vdisp_data, v_data):\n",
    "    \"\"\"create a comprehensive 4x3 comparison plot.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # set up the figure\n",
    "        fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "        fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # get the data shapes and coordinate setup\n",
    "        ni, nj = post_b3d.data.shape[:2]\n",
    "        \n",
    "        # create coordinate arrays for proper axis labelling\n",
    "        if coord_info:\n",
    "            x_min = coord_info.get('x_min')\n",
    "            x_max = coord_info.get('x_max') \n",
    "            y_min = coord_info.get('y_min')\n",
    "            y_max = coord_info.get('y_max')\n",
    "            # note: ra increases to the left (negative direction)\n",
    "            extent = [-x_max, -x_min, y_min, y_max]\n",
    "        else:\n",
    "            extent = [0, nj-1, 0, ni-1]\n",
    "        \n",
    "        # row 1: flux (hα - first emission line)\n",
    "        row = 0\n",
    "        \n",
    "        # model (preconvolved)\n",
    "        flux_model = post_b3d.maps[sample, 0]  # first line flux\n",
    "        flux_model_safe = np.where(flux_model > 0, flux_model, np.nan)\n",
    "        im1 = axes[row, 0].imshow(np.log10(flux_model_safe), extent=extent, \n",
    "                                 origin='lower', cmap='viridis')\n",
    "        axes[row, 0].set_title('Model')\n",
    "        axes[row, 0].set_ylabel('ΔDec (″)')\n",
    "        \n",
    "        # convolved model  \n",
    "        flux_conv = fit[0] #post_b3d.con_cubes[sample].sum(axis=2)  # integrate over wavelength\n",
    "        flux_conv_safe = np.where(flux_conv > 0, flux_conv, np.nan)\n",
    "        im2 = axes[row, 1].imshow(flux_conv_safe, extent=extent,\n",
    "                                 origin='lower', cmap='viridis')\n",
    "        axes[row, 1].set_title('Convolved Model')\n",
    "        \n",
    "        # data\n",
    "        flux_data = post_b3d.data.sum(axis=2)  # integrate over wavelength\n",
    "        flux_data_safe = np.where(flux_data > 0, flux_data, np.nan)\n",
    "        im3 = axes[row, 2].imshow(np.log10(flux_data_safe), extent=extent,\n",
    "                                 origin='lower', cmap='viridis')\n",
    "        axes[row, 2].set_title('Data')\n",
    "        \n",
    "        # residuals\n",
    "        flux_residual = np.log10(flux_data_safe) - np.log10(flux_conv_safe)\n",
    "        residual_std = np.nanstd(flux_residual)\n",
    "        im4 = axes[row, 3].imshow(flux_residual, extent=extent, origin='lower', \n",
    "                                 cmap='RdBu_r', vmin=-3*residual_std, vmax=3*residual_std)\n",
    "        axes[row, 3].set_title('Residuals')\n",
    "        \n",
    "        # add colorbars for flux row\n",
    "        fig.colorbar(im3, ax=axes[row, 2], shrink=0.8, label='log(F(Hα))')\n",
    "        fig.colorbar(im4, ax=axes[row, 3], shrink=0.8, label='ΔF(Hα)/σF(Hα)')\n",
    "        \n",
    "        # row 2: velocity\n",
    "        row = 1\n",
    "        v_map_idx = nlines  # velocity map index\n",
    "        \n",
    "        # model velocity\n",
    "        v_model = post_b3d.maps[sample, v_map_idx]\n",
    "        im5 = axes[row, 0].imshow(v_model, extent=extent, origin='lower', \n",
    "                                 cmap='RdBu_r', vmin=-80, vmax=80)\n",
    "        axes[row, 0].set_ylabel('ΔDec (″)')\n",
    "        \n",
    "        # convolved model velocity (from fit if available)\n",
    "        if fit is not None and fit.shape[0] > 2:\n",
    "            v_conv = fit[2]\n",
    "            im6 = axes[row, 1].imshow(v_conv, extent=extent, origin='lower',\n",
    "                                     cmap='RdBu_r', vmin=-80, vmax=80)\n",
    "        else:\n",
    "            # fallback to model if fit failed\n",
    "            im6 = axes[row, 1].imshow(v_model, extent=extent, origin='lower',\n",
    "                                     cmap='RdBu_r', vmin=-80, vmax=80)\n",
    "            v_conv = v_model\n",
    "        \n",
    "        im7 = axes[row, 2].imshow(v_data, extent=extent, origin='lower',\n",
    "                                 cmap='RdBu_r', vmin=-80, vmax=80)\n",
    "        \n",
    "        # velocity residuals\n",
    "        v_residual = v_data - v_conv\n",
    "        v_res_std = np.nanstd(v_residual)\n",
    "        if v_res_std > 0:\n",
    "            im8 = axes[row, 3].imshow(v_residual, extent=extent, origin='lower',\n",
    "                                     cmap='RdBu_r', vmin=-3*v_res_std, vmax=3*v_res_std)\n",
    "        else:\n",
    "            im8 = axes[row, 3].imshow(v_residual, extent=extent, origin='lower', cmap='RdBu_r')\n",
    "        \n",
    "        # add colorbars for velocity row\n",
    "        fig.colorbar(im7, ax=axes[row, 2], shrink=0.8, label='v (km/s)')\n",
    "        fig.colorbar(im8, ax=axes[row, 3], shrink=0.8, label='Δv (km/s)')\n",
    "        \n",
    "        # row 3: velocity dispersion  \n",
    "        row = 2\n",
    "        vdisp_map_idx = nlines + 1  # velocity dispersion map index\n",
    "        \n",
    "        # model velocity dispersion\n",
    "        vdisp_model = post_b3d.maps[sample, vdisp_map_idx]\n",
    "        im9 = axes[row, 0].imshow(vdisp_model, extent=extent, origin='lower',\n",
    "                                 cmap='viridis', vmin=15, vmax=40)\n",
    "        axes[row, 0].set_ylabel('ΔDec (″)')\n",
    "        axes[row, 0].set_xlabel('ΔRA (″)')\n",
    "        \n",
    "        # convolved model velocity dispersion (from fit if available)\n",
    "        if fit is not None and fit.shape[0] > 3:\n",
    "            vdisp_conv = fit[3]\n",
    "            im10 = axes[row, 1].imshow(vdisp_conv, extent=extent, origin='lower',\n",
    "                                      cmap='viridis', vmin=15, vmax=40)\n",
    "        else:\n",
    "            # fallback to model if fit failed\n",
    "            im10 = axes[row, 1].imshow(vdisp_model, extent=extent, origin='lower',\n",
    "                                      cmap='viridis', vmin=15, vmax=40)\n",
    "            vdisp_conv = vdisp_model\n",
    "        \n",
    "        axes[row, 1].set_xlabel('ΔRA (″)')\n",
    "        \n",
    "        # for \"data\" velocity dispersion, use fitted values\n",
    "        im11 = axes[row, 2].imshow(vdisp_data, extent=extent, origin='lower',\n",
    "                                  cmap='viridis', vmin=15, vmax=40)\n",
    "        axes[row, 2].set_xlabel('ΔRA (″)')\n",
    "        \n",
    "        # velocity dispersion residuals\n",
    "        vdisp_residual = vdisp_data - vdisp_conv\n",
    "        vdisp_res_std = np.nanstd(vdisp_residual)\n",
    "        if vdisp_res_std > 0:\n",
    "            im12 = axes[row, 3].imshow(vdisp_residual, extent=extent, origin='lower',\n",
    "                                      cmap='RdBu_r', vmin=-3*vdisp_res_std, vmax=3*vdisp_res_std)\n",
    "        else:\n",
    "            im12 = axes[row, 3].imshow(vdisp_residual, extent=extent, origin='lower', cmap='RdBu_r')\n",
    "        axes[row, 3].set_xlabel('ΔRA (″)')\n",
    "        \n",
    "        # add colorbars for velocity dispersion row\n",
    "        fig.colorbar(im11, ax=axes[row, 2], shrink=0.8, label='σᵥ (km/s)')\n",
    "        fig.colorbar(im12, ax=axes[row, 3], shrink=0.8, label='Δσᵥ (km/s)')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return fig, axes\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating comparison plot: {e}\")\n",
    "        return None, None\n",
    "\n",
    "fig, axes = create_comprehensive_comparison_plot(\n",
    "    post_b3d, fit, sample, nlines, coord_info, aligned_vdisp, aligned_v)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PhD Virtual Env",
   "language": "python",
   "name": "phd-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
